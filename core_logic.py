import asyncio
import random
import os
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from litellm import acompletion, embedding
import plotly.express as px

# --- C·∫§U H√åNH ---
CONFIG = {
    "SIMULATION_MODE": False,     # M·∫∑c ƒë·ªãnh t·∫Øt gi·∫£ l·∫≠p ƒë·ªÉ nh·∫Øc b·∫°n nh·∫≠p Key
    "TOTAL_AGENTS": 10,           # 10 chuy√™n gia l√† ƒë·ªß ƒë·ªÉ ra quy·∫øt ƒë·ªãnh s√¢u s·∫Øc
    "FILTER_KEEP": 3,             # Gi·ªØ l·∫°i 3 lu·ªìng √Ω ki·∫øn ch√≠nh
    "REAL_MODEL": "gpt-4o-mini",  # Model th√¥ng minh v√† r·∫ª
    "TIMEOUT": 60
}

# --- DANH S√ÅCH VAI DI·ªÑN CHUY√äN BI·ªÜT CHO NH√Ä M√ÅY ---
# ƒê√£ x√≥a B√°c sƒ©/Hacker, thay b·∫±ng ƒë·ªôi ng≈© qu·∫£n tr·ªã doanh nghi·ªáp
ROLES_DB = [
    "Gi√°m ƒë·ªëc T√†i ch√≠nh (CFO)", 
    "Gi√°m ƒë·ªëc S·∫£n xu·∫•t (Factory Manager)", 
    "Tr∆∞·ªüng ph√≤ng Qu·∫£n l√Ω Ch·∫•t l∆∞·ª£ng (QC Manager)", 
    "Gi√°m ƒë·ªëc Kinh doanh (Sales Director)", 
    "K·∫ø to√°n tr∆∞·ªüng", 
    "K·ªπ s∆∞ Quy tr√¨nh (Process Engineer)",
    "Chuy√™n gia Chu·ªói cung ·ª©ng",
    "Lu·∫≠t s∆∞ Th∆∞∆°ng m·∫°i"
]

class AIAgent:
    def __init__(self, agent_id):
        self.id = f"Agent_{agent_id:03d}"
        self.role = random.choice(ROLES_DB)
        
    async def process(self, user_question, semaphore):
        async with semaphore:
            try:
                # --- CH·∫æ ƒê·ªò GI·∫¢ L·∫¨P (M·∫´u tr·∫£ l·ªùi v·ªÅ Bavia) ---
                if CONFIG["SIMULATION_MODE"]:
                    await asyncio.sleep(random.uniform(0.5, 1.5))
                    if "CFO" in self.role or "T√†i ch√≠nh" in self.role:
                        content = f"[{self.role}] V·ªÅ m·∫∑t t√†i ch√≠nh, l√¥ h√†ng Bavia n√†y n√™n H·ª¶Y. Chi ph√≠ s·ª≠a ch·ªØa (Rework) t·ªën 15% margin, r·ªßi ro kh√°ch tr·∫£ h√†ng cao g·∫•p ƒë√¥i."
                    elif "S·∫£n xu·∫•t" in self.role:
                        content = f"[{self.role}] T√¥i ƒë·ªÅ xu·∫•t s·ª≠a l·∫°i khu√¥n ngay l·∫≠p t·ª©c. Cho c√¥ng nh√¢n tƒÉng ca x·ª≠ l√Ω l√¥ n√†y ƒë·ªÉ k·ªãp ti·∫øn ƒë·ªô."
                    else:
                        content = f"[{self.role}] C·∫ßn xem l·∫°i h·ª£p ƒë·ªìng v·ªõi kh√°ch h√†ng v·ªÅ ti√™u chu·∫©n ch·∫•p nh·∫≠n l·ªói ngo·∫°i quan."
                    
                    vector = np.random.rand(1536).tolist()
                    return {"id": self.id, "role": self.role, "content": content, "vector": vector, "status": "SUCCESS"}

                # --- CH·∫æ ƒê·ªò TH·ª∞C CHI·∫æN (G·ªåI API) ---
                else:
                    # Prompt chuy√™n s√¢u cho vai di·ªÖn
                    prompt = f"""
                    B·∫°n ƒëang ƒë√≥ng vai: {self.role} t·∫°i m·ªôt nh√† m√°y s·∫£n xu·∫•t l·ªõn.
                    V·∫•n ƒë·ªÅ ƒëang ƒë∆∞·ª£c th·∫£o lu·∫≠n: "{user_question}"
                    
                    NHI·ªÜM V·ª§:
                    1. Ph√¢n t√≠ch v·∫•n ƒë·ªÅ d·ª±a tr√™n L·ª¢I √çCH C·ªêT L√ïI c·ªßa v·ªã tr√≠ b·∫°n n·∫Øm gi·ªØ (V√≠ d·ª•: CFO ch·ªâ quan t√¢m d√≤ng ti·ªÅn/l·ª£i nhu·∫≠n, QC quan t√¢m uy t√≠n).
                    2. ƒê∆∞a ra con s·ªë gi·∫£ ƒë·ªãnh ho·∫∑c quy tr√¨nh c·ª• th·ªÉ.
                    3. Quy·∫øt ƒë·ªãnh d·ª©t kho√°t: S·ª≠a (Rework) hay H·ªßy (Scrap)?
                    """
                    
                    response = await acompletion(
                        model=CONFIG["REAL_MODEL"],
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.7
                    )
                    content_text = response.choices[0].message.content

                    emb_res = await embedding(
                        model="text-embedding-3-small",
                        input=[content_text]
                    )
                    vector_data = emb_res.data[0]['embedding']

                    return {"id": self.id, "role": self.role, "content": content_text, "vector": vector_data, "status": "SUCCESS"}

            except Exception as e:
                return {"id": self.id, "status": "ERROR", "error": str(e)}

class GrandCouncilPipeline:
    def __init__(self):
        pass

    async def run(self, user_question, st_status, st_progress, st_logs):
        concurrency = 5 
        sem = asyncio.Semaphore(concurrency)
        
        # T·∫°o Agent
        agents = [AIAgent(i) for i in range(CONFIG["TOTAL_AGENTS"])]
        tasks = [agent.process(user_question, sem) for agent in agents]
        
        results = []
        completed = 0
        
        for f in asyncio.as_completed(tasks):
            res = await f
            results.append(res)
            completed += 1
            if st_progress: st_progress.progress(int((completed / CONFIG["TOTAL_AGENTS"]) * 70))
            if st_logs and completed <= 3:
                st_logs[0].write(f"üë§ **{res.get('role')}**: {res.get('content')[:150]}...")

        valid_data = [r for r in results if r["status"] == "SUCCESS"]
        if not valid_data: return "L·ªói k·∫øt n·ªëi API. H√£y ki·ªÉm tra Key.", None

        # Ph√¢n c·ª•m
        if st_logs: st_logs[1].info("ƒêang ph√¢n t√≠ch m√¢u thu·∫´n gi·ªØa c√°c ph√≤ng ban...")
        vectors = np.array([item['vector'] for item in valid_data])
        
        kmeans = KMeans(n_clusters=min(CONFIG["FILTER_KEEP"], len(valid_data)), n_init=10)
        kmeans.fit(vectors)
        
        representatives = []
        df_for_chart = []
        
        seen = set()
        for i, label in enumerate(kmeans.labels_):
            item = valid_data[i]
            df_for_chart.append({
                "Role": item['role'], "Cluster": str(label), 
                "Content": item['content'][:100], 
                "x": vectors[i][0], "y": vectors[i][1]
            })
            
            if label not in seen:
                representatives.append(item)
                seen.add(label)
                if st_logs: st_logs[1].write(f"- Quan ƒëi·ªÉm {label+1}: {item['role']}")

        # T·ªïng h·ª£p
        if st_logs: st_logs[2].info("CFO v√† Gi√°m ƒë·ªëc nh√† m√°y ƒëang ch·ªët ph∆∞∆°ng √°n...")
        final_ans = await self.final_synthesis(representatives, user_question)
        
        if st_progress: st_progress.progress(100)
        return final_ans, pd.DataFrame(df_for_chart)

    async def final_synthesis(self, reps, q):
        context = "\n".join([f"- {r['role']} ƒë·ªÅ xu·∫•t: {r['content']}" for r in reps])
        
        if CONFIG["SIMULATION_MODE"]:
            return f"**T·ªîNG H·ª¢P GI·∫¢ L·∫¨P:**\n{context}"
        else:
            prompt = f"""
            B·∫°n l√† T·ªïng Gi√°m ƒê·ªëc (CEO). D∆∞·ªõi ƒë√¢y l√† tranh lu·∫≠n gi·ªØa c√°c tr∆∞·ªüng ph√≤ng v·ªÅ v·∫•n ƒë·ªÅ: "{q}"
            
            {context}
            
            Y√äU C·∫¶U:
            1. T√≥m t·∫Øt xung ƒë·ªôt ch√≠nh (V√≠ d·ª•: T√†i ch√≠nh mu·ªën h·ªßy ƒë·ªÉ c·∫Øt l·ªó, nh∆∞ng S·∫£n xu·∫•t mu·ªën s·ª≠a ƒë·ªÉ k·ªãp giao h√†ng).
            2. ƒê∆∞a ra QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG (Final Verdict) d·ª±a tr√™n t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n.
            3. L·∫≠p b·∫£ng so s√°nh ng·∫Øn g·ªçn.
            """
            try:
                response = await acompletion(
                    model=CONFIG["REAL_MODEL"],
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                return "L·ªói t·ªïng h·ª£p."
