import asyncio
import json
import random
import time
import os
import psutil
import numpy as np
import uuid
from datetime import datetime
from sklearn.cluster import KMeans
import chromadb
from chromadb.utils import embedding_functions

# Import th∆∞ vi·ªán g·ªçi AI ƒëa nƒÉng
from litellm import acompletion, embedding

# ==============================================================================
# ‚öôÔ∏è C·∫§U H√åNH H·ªÜ TH·ªêNG (SYSTEM CONFIG)
# ==============================================================================
CONFIG = {
    "SIMULATION_MODE": True,        # M·∫∑c ƒë·ªãnh True ƒë·ªÉ test nhanh. Chuy·ªÉn False trong app.py ƒë·ªÉ ch·∫°y th·∫≠t
    "TOTAL_AGENTS": 50,             # S·ªë l∆∞·ª£ng m·∫∑c ƒë·ªãnh
    "FILTER_KEEP": 5,               # S·ªë ƒë·∫°i di·ªán gi·ªØ l·∫°i
    "SYSTEM_BUFFER_RAM_GB": 1.5,    # RAM ch·ª´a l·∫°i cho OS
    "DB_PATH": "./brain_memory",    # ƒê∆∞·ªùng d·∫´n l∆∞u DB
    "REAL_MODEL": "gpt-3.5-turbo",  # Model ch·∫°y th·∫≠t
    "TIMEOUT_SECONDS": 45           # Th·ªùi gian ch·ªù t·ªëi ƒëa cho 1 agent
}

# ==============================================================================
# üõ†Ô∏è MODULE 1: B√ÅC Sƒ® H·ªÜ TH·ªêNG (SYSTEM OPTIMIZER)
# ==============================================================================
class SystemOptimizer:
    @staticmethod
    def calculate_safe_concurrency(agent_count):
        """T√≠nh to√°n s·ªë lu·ªìng an to√†n d·ª±a tr√™n RAM th·ª±c t·∫ø c·ªßa VPS"""
        try:
            mem = psutil.virtual_memory()
            available_gb = mem.available / (1024**3)
            
            # ∆Ø·ªõc t√≠nh: 1 Thread Python + Network overhead ~ 60MB
            ram_per_thread_gb = 0.06 
            usable_ram = available_gb - CONFIG["SYSTEM_BUFFER_RAM_GB"]
            
            if usable_ram <= 0.2:
                return 2 # Ch·∫ø ƒë·ªô sinh t·ªìn (Low Memory)
                
            optimal_threads = int(usable_ram / ram_per_thread_gb)
            
            # Gi·ªõi h·∫°n tr·∫ßn: Kh√¥ng qu√° 50 lu·ªìng ƒë·ªÉ tr√°nh ngh·∫Ωn CPU/IO
            # V√† kh√¥ng l·ªõn h∆°n t·ªïng s·ªë agent y√™u c·∫ßu
            final_concurrency = min(optimal_threads, 50, agent_count)
            
            return max(2, final_concurrency) # Lu√¥n ch·∫°y √≠t nh·∫•t 2 lu·ªìng
        except:
            return 5 # Fallback an to√†n n·∫øu kh√¥ng ƒëo ƒë∆∞·ª£c RAM

# ==============================================================================
# üß† MODULE 2: B·ªò NH·ªö T·ª∞ H·ªåC (RAG MEMORY)
# ==============================================================================
class KnowledgeBrain:
    def __init__(self):
        try:
            # Kh·ªüi t·∫°o Client ChromaDB
            self.client = chromadb.PersistentClient(path=CONFIG["DB_PATH"])
            
            # N·∫øu ch·∫°y th·∫≠t th√¨ d√πng model embedding chu·∫©n, gi·∫£ l·∫≠p th√¨ d√πng m·∫∑c ƒë·ªãnh
            self.collection = self.client.get_or_create_collection(name="ai_hive_mind")
            self.is_active = True
        except Exception as e:
            print(f"Memory Error: {str(e)}")
            self.is_active = False

    def memorize(self, question, answer, score):
        if not self.is_active or score < 85: return
        
        try:
            # L∆∞u v√†o DB
            self.collection.add(
                documents=[answer],
                metadatas=[{
                    "question": question, 
                    "score": score, 
                    "timestamp": str(datetime.now())
                }],
                ids=[str(uuid.uuid4())]
            )
        except Exception as e:
            print(f"Save Memory Error: {e}")

    def recall(self, question):
        if not self.is_active: return []
        try:
            results = self.collection.query(
                query_texts=[question],
                n_results=2
            )
            if results['documents'] and results['documents'][0]:
                return results['documents'][0]
        except:
            pass
        return []

# ==============================================================================
# ü§ñ MODULE 3: AI AGENT WORKER
# ==============================================================================
class AIAgent:
    def __init__(self, agent_id):
        self.id = f"Agent_{agent_id:03d}"
        self.roles = ["K·ªπ s∆∞ H·ªá th·ªëng", "Lu·∫≠t s∆∞ R·ªßi ro", "Hacker M≈© tr·∫Øng", 
                      "Nh√† Kinh t·∫ø h·ªçc", "Ng∆∞·ªùi d√πng kh√≥ t√≠nh", "Chuy√™n gia UX/UI", 
                      "Nh√† ƒê·∫°o ƒë·ª©c AI", "CEO Startup"]
        self.role = random.choice(self.roles)
        
    async def process(self, prompt, context, semaphore):
        async with semaphore: # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ch·∫°y c√πng l√∫c
            try:
                # 1. Ch·∫ø ƒë·ªô Gi·∫£ l·∫≠p (Si√™u nhanh, kh√¥ng t·ªën ti·ªÅn)
                if CONFIG["SIMULATION_MODE"]:
                    delay = random.uniform(0.5, 1.5)
                    await asyncio.sleep(delay)
                    
                    content = f"[{self.role}] T√¥i ƒë·ªÅ xu·∫•t gi·∫£i ph√°p m√£ s·ªë {random.randint(1000,9999)}. " \
                              f"Quan ƒëi·ªÉm c·ªßa t√¥i t·∫≠p trung v√†o {random.choice(['T·ªëi ∆∞u chi ph√≠', 'B·∫£o m·∫≠t', 'Tr·∫£i nghi·ªám ng∆∞·ªùi d√πng'])}. " \
                              f"C·∫ßn l∆∞u √Ω r·ªßi ro v·ªÅ {random.choice(['ph√°p l√Ω', 'h·∫° t·∫ßng', 'nh√¢n s·ª±'])}."
                    
                    # Vector gi·∫£ l·∫≠p (128 chi·ªÅu)
                    vector = np.random.rand(128).tolist()
                    
                    return {
                        "id": self.id, "role": self.role, "content": content,
                        "vector": vector, "status": "SUCCESS"
                    }

                # 2. Ch·∫ø ƒë·ªô CH·∫†Y TH·∫¨T (G·ªçi API)
                else:
                    system_msg = f"B·∫°n l√† {self.role}. Nhi·ªám v·ª•: Ph√¢n t√≠ch v·∫•n ƒë·ªÅ v√† ƒë∆∞a ra gi·∫£i ph√°p ng·∫Øn g·ªçn, s·∫Øc b√©n."
                    if context:
                        system_msg += f"\nTham kh·∫£o kinh nghi·ªám qu√° kh·ª©: {context}"
                    
                    # G·ªçi LLM sinh text
                    response = await acompletion(
                        model=CONFIG["REAL_MODEL"],
                        messages=[
                            {"role": "system", "content": system_msg},
                            {"role": "user", "content": prompt}
                        ],
                        timeout=CONFIG["TIMEOUT_SECONDS"]
                    )
                    content_text = response.choices[0].message.content

                    # G·ªçi API t·∫°o Vector (Embedding) ƒë·ªÉ d√πng cho b∆∞·ªõc ph√¢n c·ª•m
                    # L∆∞u √Ω: ƒê·ªÉ ti·∫øt ki·ªám, ta c√≥ th·ªÉ d√πng model 'text-embedding-3-small' c·ªßa OpenAI
                    emb_response = await embedding(
                        model="text-embedding-3-small",
                        input=[content_text]
                    )
                    vector_data = emb_response.data[0]['embedding']

                    return {
                        "id": self.id, "role": self.role, "content": content_text,
                        "vector": vector_data, "status": "SUCCESS"
                    }

            except Exception as e:
                return {"id": self.id, "status": "ERROR", "error": str(e)}

# ==============================================================================
# ‚öôÔ∏è MODULE 4: ORCHESTRATOR (ƒê·∫†I H·ªòI ƒê·ªíNG)
# ==============================================================================
class GrandCouncilPipeline:
    def __init__(self):
        self.brain = KnowledgeBrain()
        
    async def run(self, user_question, st_status_container=None, st_progress_bar=None, st_log_containers=None):
        """
        H√†m ch·∫°y ch√≠nh, h·ªó tr·ª£ c·∫≠p nh·∫≠t giao di·ªán Streamlit
        st_status_container: N∆°i hi·ªán text tr·∫°ng th√°i
        st_progress_bar: Thanh ti·∫øn tr√¨nh
        st_log_containers: List 3 container (expander) ƒë·ªÉ ghi log chi ti·∫øt
        """
        
        # 1. T√≠nh to√°n t√†i nguy√™n
        concurrency = SystemOptimizer.calculate_safe_concurrency(CONFIG["TOTAL_AGENTS"])
        sem = asyncio.Semaphore(concurrency)
        
        # Helper ƒë·ªÉ update UI an to√†n
        def update_ui(text, progress):
            if st_status_container: st_status_container.markdown(f"**Tr·∫°ng th√°i:** {text}")
            if st_progress_bar: st_progress_bar.progress(progress)
            
        update_ui(f"ƒêang t·ªëi ∆∞u h·ªá th·ªëng... Ch·∫°y {concurrency} lu·ªìng song song.", 5)
        
        # --- B∆Ø·ªöC 0: RECALL (NH·ªö L·∫†I) ---
        past_lessons = self.brain.recall(user_question)
        context_str = ""
        if past_lessons:
            context_str = "\n".join(past_lessons)
            if st_log_containers:
                st_log_containers[0].info(f"üîÆ T√¨m th·∫•y {len(past_lessons)} b√†i h·ªçc t·ª´ qu√° kh·ª©.")

        # --- B∆Ø·ªöC 1: EXPANSION (1 -> 100) ---
        agents = [AIAgent(i) for i in range(CONFIG["TOTAL_AGENTS"])]
        tasks = [agent.process(user_question, context_str, sem) for agent in agents]
        
        update_ui(f"K√≠ch ho·∫°t {CONFIG['TOTAL_AGENTS']} Agents...", 10)
        
        # Ch·∫°y v√† hi·ªÉn th·ªã ti·∫øn ƒë·ªô realtime
        results = []
        completed = 0
        for f in asyncio.as_completed(tasks):
            res = await f
            results.append(res)
            completed += 1
            # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh t·ª´ 10% -> 60%
            prog = 10 + int((completed / CONFIG["TOTAL_AGENTS"]) * 50)
            if st_progress_bar: st_progress_bar.progress(prog)
            
            # Hi·ªán log m·∫´u v√†i con ƒë·∫ßu ti√™n
            if st_log_containers and completed <= 5:
                if res.get("status") == "SUCCESS":
                    st_log_containers[0].write(f"‚úÖ **{res['role']}**: {res['content'][:100]}...")
                else:
                    st_log_containers[0].error(f"‚ùå Error: {res.get('error')}")

        valid_data = [r for r in results if r["status"] == "SUCCESS"]
        if not valid_data:
            update_ui("‚ùå Th·∫•t b·∫°i: Kh√¥ng c√≥ Agent n√†o tr·∫£ l·ªùi th√†nh c√¥ng.", 0)
            return "System Error"

        update_ui(f"Thu th·∫≠p xong {len(valid_data)} √Ω ki·∫øn. ƒêang ph√¢n t√≠ch...", 65)

        # --- B∆Ø·ªöC 2: FILTERING (100 -> 10) ---
        if st_log_containers:
            st_log_containers[1].info("ƒêang ch·∫°y thu·∫≠t to√°n K-Means Clustering...")
        
        # L·∫•y vector ra ƒë·ªÉ ph√¢n c·ª•m
        vectors = np.array([item['vector'] for item in valid_data])
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p s·ªë l∆∞·ª£ng data √≠t h∆°n s·ªë cluster y√™u c·∫ßu
        n_clusters = min(CONFIG["FILTER_KEEP"], len(valid_data))
        if n_clusters < 2: n_clusters = 1
            
        kmeans = KMeans(n_clusters=n_clusters, n_init=10)
        kmeans.fit(vectors)
        
        representatives = []
        seen_clusters = set()
        
        # Ch·ªçn ƒë·∫°i di·ªán cho t·ª´ng c·ª•m
        for i, label in enumerate(kmeans.labels_):
            if label not in seen_clusters:
                item = valid_data[i]
                representatives.append(item)
                seen_clusters.add(label)
                # Log ra UI
                if st_log_containers:
                    st_log_containers[1].markdown(f"- **Nh√≥m quan ƒëi·ªÉm {label+1}** (ƒê·∫°i di·ªán: {item['role']})")
                
                if len(seen_clusters) >= n_clusters: break
        
        update_ui(f"ƒê√£ c√¥ ƒë·∫∑c th√†nh {len(representatives)} lu·ªìng t∆∞ t∆∞·ªüng ch√≠nh.", 80)

        # --- B∆Ø·ªöC 3: SYNTHESIS & DEBATE (10 -> 1) ---
        if st_log_containers:
            st_log_containers[2].info("H·ªôi ƒë·ªìng T·ªëi cao ƒëang tranh bi·ªán v√† t·ªïng h·ª£p...")
            
        final_answer, confidence = await self.final_synthesis(representatives, user_question)
        
        # --- B∆Ø·ªöC 4: MEMORIZE (T·ª∞ H·ªåC) ---
        self.brain.memorize(user_question, final_answer, confidence)
        
        update_ui("Ho√†n t·∫•t!", 100)
        return final_answer

    async def final_synthesis(self, representatives, original_question):
        """T·ªïng h·ª£p cu·ªëi c√πng (Gi·∫£ l·∫≠p ho·∫∑c g·ªçi API)"""
        
        # T·ªïng h·ª£p input
        summary_input = "\n".join([f"- [{item['role']}]: {item['content']}" for item in representatives])
        
        if CONFIG["SIMULATION_MODE"]:
            await asyncio.sleep(1.5)
            # T·∫°o c√¢u tr·∫£ l·ªùi gi·∫£ l·∫≠p c√≥ c·∫•u tr√∫c
            final_output = f"""
            ### üèõÔ∏è QUY·∫æT NGH·ªä C·ª¶A H·ªòI ƒê·ªíNG
            
            **1. Ph√¢n t√≠ch ƒëa chi·ªÅu:**
            H·ªá th·ªëng ƒë√£ ghi nh·∫≠n {CONFIG['TOTAL_AGENTS']} √Ω ki·∫øn, c√¥ ƒë·ªçng th√†nh {len(representatives)} nh√≥m quan ƒëi·ªÉm ch√≠nh.
            
            **2. Gi·∫£i ph√°p c·ªët l√µi:**
            D·ª±a tr√™n ƒë·ªÅ xu·∫•t c·ªßa nh√≥m {representatives[0]['role']}, ch√∫ng t√¥i ki·∫øn ngh·ªã gi·∫£i ph√°p lai (Hybrid Approach).
            
            **3. Ki·ªÉm so√°t r·ªßi ro:**
            ƒê√£ t√≠ch h·ª£p c·∫£nh b√°o t·ª´ nh√≥m {representatives[-1]['role']} ƒë·ªÉ gi·∫£m thi·ªÉu r·ªßi ro v·∫≠n h√†nh.
            
            *(D·ªØ li·ªáu ƒë∆∞·ª£c t·∫°o b·ªüi ch·∫ø ƒë·ªô Gi·∫£ l·∫≠p. H√£y nh·∫≠p API Key ƒë·ªÉ ch·∫°y th·∫≠t)*
            """
            return final_output, random.randint(88, 98)
        
        else:
            # G·ªåI API ƒê·ªÇ T·ªîNG H·ª¢P TH·∫¨T (M√¥ h√¨nh Tranh bi·ªán)
            prompt = f"""
            B·∫°n l√† Ch·ªß t·ªça H·ªôi ƒë·ªìng AI. D∆∞·ªõi ƒë√¢y l√† c√°c lu·ªìng √Ω ki·∫øn ƒë·∫°i di·ªán t·ª´ {CONFIG['TOTAL_AGENTS']} chuy√™n gia v·ªÅ v·∫•n ƒë·ªÅ: "{original_question}"
            
            {summary_input}
            
            NHI·ªÜM V·ª§:
            1. T·ªïng h·ª£p c√°c ƒëi·ªÉm chung.
            2. Gi·∫£i quy·∫øt m√¢u thu·∫´n gi·ªØa c√°c nh√≥m.
            3. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng to√†n di·ªán, chi ti·∫øt v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao.
            4. Tr√¨nh b√†y ƒë·ªãnh d·∫°ng Markdown ƒë·∫πp.
            """
            
            try:
                response = await acompletion(
                    model=CONFIG["REAL_MODEL"],
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content, 95
            except Exception as e:
                return f"L·ªói t·ªïng h·ª£p: {str(e)}", 0